{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab36aae8",
   "metadata": {},
   "source": [
    "BÀI 3.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540a86b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 2.3.4\n",
      "\n",
      "NumPy build configuration:\n",
      "{\n",
      "  \"Compilers\": {\n",
      "    \"c\": {\n",
      "      \"name\": \"msvc\",\n",
      "      \"linker\": \"link\",\n",
      "      \"version\": \"19.44.35217\",\n",
      "      \"commands\": \"cl\"\n",
      "    },\n",
      "    \"cython\": {\n",
      "      \"name\": \"cython\",\n",
      "      \"linker\": \"cython\",\n",
      "      \"version\": \"3.1.4\",\n",
      "      \"commands\": \"cython\"\n",
      "    },\n",
      "    \"c++\": {\n",
      "      \"name\": \"msvc\",\n",
      "      \"linker\": \"link\",\n",
      "      \"version\": \"19.44.35217\",\n",
      "      \"commands\": \"cl\"\n",
      "    }\n",
      "  },\n",
      "  \"Machine Information\": {\n",
      "    \"host\": {\n",
      "      \"cpu\": \"x86_64\",\n",
      "      \"family\": \"x86_64\",\n",
      "      \"endian\": \"little\",\n",
      "      \"system\": \"windows\"\n",
      "    },\n",
      "    \"build\": {\n",
      "      \"cpu\": \"x86_64\",\n",
      "      \"family\": \"x86_64\",\n",
      "      \"endian\": \"little\",\n",
      "      \"system\": \"windows\"\n",
      "    }\n",
      "  },\n",
      "  \"Build Dependencies\": {\n",
      "    \"blas\": {\n",
      "      \"name\": \"scipy-openblas\",\n",
      "      \"found\": true,\n",
      "      \"version\": \"0.3.30\",\n",
      "      \"detection method\": \"pkgconfig\",\n",
      "      \"include directory\": \"C:/Users/runneradmin/AppData/Local/Temp/cibw-run-0fv2o5t8/cp313-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/include\",\n",
      "      \"lib directory\": \"C:/Users/runneradmin/AppData/Local/Temp/cibw-run-0fv2o5t8/cp313-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/lib\",\n",
      "      \"openblas configuration\": \"OpenBLAS 0.3.30  USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell MAX_THREADS=24\",\n",
      "      \"pc file directory\": \"D:/a/numpy-release/numpy-release/.openblas\"\n",
      "    },\n",
      "    \"lapack\": {\n",
      "      \"name\": \"scipy-openblas\",\n",
      "      \"found\": true,\n",
      "      \"version\": \"0.3.30\",\n",
      "      \"detection method\": \"pkgconfig\",\n",
      "      \"include directory\": \"C:/Users/runneradmin/AppData/Local/Temp/cibw-run-0fv2o5t8/cp313-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/include\",\n",
      "      \"lib directory\": \"C:/Users/runneradmin/AppData/Local/Temp/cibw-run-0fv2o5t8/cp313-win_amd64/build/venv/Lib/site-packages/scipy_openblas64/lib\",\n",
      "      \"openblas configuration\": \"OpenBLAS 0.3.30  USE64BITINT DYNAMIC_ARCH NO_AFFINITY Haswell MAX_THREADS=24\",\n",
      "      \"pc file directory\": \"D:/a/numpy-release/numpy-release/.openblas\"\n",
      "    }\n",
      "  },\n",
      "  \"Python Information\": {\n",
      "    \"path\": \"C:\\\\Users\\\\runneradmin\\\\AppData\\\\Local\\\\Temp\\\\build-env-x2rtzeej\\\\Scripts\\\\python.exe\",\n",
      "    \"version\": \"3.13\"\n",
      "  },\n",
      "  \"SIMD Extensions\": {\n",
      "    \"baseline\": [\n",
      "      \"SSE\",\n",
      "      \"SSE2\",\n",
      "      \"SSE3\"\n",
      "    ],\n",
      "    \"found\": [\n",
      "      \"SSSE3\",\n",
      "      \"SSE41\",\n",
      "      \"POPCNT\",\n",
      "      \"SSE42\",\n",
      "      \"AVX\",\n",
      "      \"F16C\",\n",
      "      \"FMA3\",\n",
      "      \"AVX2\"\n",
      "    ],\n",
      "    \"not found\": [\n",
      "      \"AVX512F\",\n",
      "      \"AVX512CD\",\n",
      "      \"AVX512_SKX\",\n",
      "      \"AVX512_CLX\",\n",
      "      \"AVX512_CNL\",\n",
      "      \"AVX512_ICL\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"\\nNumPy build configuration:\")\n",
    "np.show_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b102a",
   "metadata": {},
   "source": [
    "BÀI 3.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d1016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr: [0 1 2 3 4 5 6 7 8 9]\n",
      "dtype: int64\n",
      "shape: (10,)\n",
      "size: 10\n",
      "arr_even: [0 2 4 6 8]\n",
      "arr_odd: [1 3 5 7 9]\n",
      "arr_update_1: [  0 100   2 100   4 100   6 100   8 100]\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "arr = np.arange(10)\n",
    "print(\"arr:\", arr)\n",
    "print(\"dtype:\", arr.dtype)\n",
    "print(\"shape:\", arr.shape)\n",
    "print(\"size:\", arr.size)\n",
    "\n",
    "# 2.\n",
    "arr_even = arr[arr % 2 == 0]\n",
    "arr_odd = arr[arr % 2 == 1]\n",
    "print(\"arr_even:\", arr_even)\n",
    "print(\"arr_odd:\", arr_odd)\n",
    "\n",
    "# 3.\n",
    "arr_update_1 = arr.copy()\n",
    "arr_update_1[arr_update_1 % 2 == 1] = 100\n",
    "print(\"arr_update_1:\", arr_update_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d510f8d",
   "metadata": {},
   "source": [
    "BÀI 3.3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ac0e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr_c (unique intersection): [2 4]\n",
      "arr_d (unique in arr_a only): [1 3 5 6]\n",
      "arr_e: [  2   6   1   9  10   3  27   8   6  25 161]\n",
      "arr_f (values 5..10): [ 6  9 10  8  6]\n"
     ]
    }
   ],
   "source": [
    "arr_a = np.array([1, 2, 3, 2, 3, 4, 3, 4, 5, 6])\n",
    "arr_b = np.array([7, 2, 10, 2, 7, 4, 9, 4, 9, 8])\n",
    "\n",
    "# 1\n",
    "arr_c = np.intersect1d(arr_a, arr_b)\n",
    "print(\"arr_c (unique intersection):\", arr_c)\n",
    "\n",
    "# 2\n",
    "arr_d = np.setdiff1d(arr_a, arr_b)\n",
    "print(\"arr_d (unique in arr_a only):\", arr_d)\n",
    "\n",
    "# 3\n",
    "arr_e = np.array([2, 6, 1, 9, 10, 3, 27, 8, 6, 25, 161])\n",
    "arr_f = arr_e[(arr_e >= 5) & (arr_e <= 10)]\n",
    "print(\"arr_e:\", arr_e)\n",
    "print(\"arr_f (values 5..10):\", arr_f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d450f",
   "metadata": {},
   "source": [
    "BÀI 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adff3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) arr_zeros: [0 0 0 0 1 0 0 0 0 0]\n",
      "2) arr_h : [24 23 22 21 20 19 18 17 16 15 14 13 12 11 10]\n",
      "3) arr_1 : [1 2 8 2 1 3 5]\n",
      "4) arr sau khi thêm 10,20: [ 1  2  8  2  1  3  5 10 20]\n",
      "5) arr sau khi thêm phân tử có giá trị là 100 vào index 5: [  1   2   8   2   1 100   3   5  10  20]\n",
      "6) arr sau khi xóa phần tử ở các index 0,1,2: [  2   1 100   3   5  10  20]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. \n",
    "arr_zeros = np.zeros(10, dtype=int)\n",
    "arr_zeros[4] = 1  \n",
    "print(\"1) arr_zeros:\", arr_zeros)\n",
    "\n",
    "# 2. \n",
    "arr_h = np.arange(10, 25)  \n",
    "print(\"2) arr_h :\", arr_h[::-1])\n",
    "\n",
    "# 3. \n",
    "arr_k = np.array((1, 2, 0, 8, 2, 0, 1, 3, 0, 5, 0), dtype=int)\n",
    "arr_1 = arr_k[arr_k != 0]\n",
    "print(\"3) arr_1 :\", arr_1)\n",
    "\n",
    "# 4. \n",
    "arr_4 = np.append(arr_1, [10, 20])\n",
    "print(\"4) arr sau khi thêm 10,20:\", arr_4)\n",
    "\n",
    "# 5. \n",
    "arr_5 = np.insert(arr_4, 5, 100)\n",
    "print(\"5) arr sau khi thêm phân tử có giá trị là 100 vào index 5:\", arr_5)\n",
    "\n",
    "# 6. \n",
    "arr_6 = np.delete(arr_5, [0, 1, 2])\n",
    "print(\"6) arr sau khi xóa phần tử ở các index 0,1,2:\", arr_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df252409",
   "metadata": {},
   "source": [
    "BÀI 3.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4cfef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng bản ghi height = 4, weight = 4\n",
      "\n",
      "arr_height (inches) -> arr_height_m (m):\n",
      "  Ví dụ 10 phần tử đầu: [4.318  4.3434 4.3688 4.3942]\n",
      "\n",
      "arr_weight (pounds) -> arr_weight_kg (kg):\n",
      "  Ví dụ 10 phần tử đầu: [27.21552  26.761928 27.669112 28.122704]\n",
      "\n",
      "arr_bmi (ví dụ 10 đầu): [1.45965884 1.41859278 1.44967582 1.45645623]\n",
      "\n",
      "Index 50 vượt quá kích thước mảng (size=4)\n",
      "\n",
      "arr_height_m[100:110] (bao gồm 110):\n",
      "[]\n",
      "\n",
      "Số cầu thủ có BMI < 21: 4\n",
      "Chỉ số (index) và BMI của những người này (tối đa 50 hiển thị):\n",
      "  index=0, BMI=1.460\n",
      "  index=1, BMI=1.419\n",
      "  index=2, BMI=1.450\n",
      "  index=3, BMI=1.456\n",
      "\n",
      "Chiều cao trung bình: 4.356 m\n",
      "Cân nặng trung bình: 27.442 kg\n",
      "\n",
      "Chiều cao lớn nhất: 4.394 m\n",
      "Cân nặng lớn nhất: 28.123 kg\n",
      "\n",
      "Chiều cao nhỏ nhất: 4.318 m\n",
      "Cân nặng nhỏ nhất: 26.762 kg\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "def read_numbers_from_file(path):\n",
    "    text = Path(path).read_text(encoding='utf-8')\n",
    "    nums = re.findall(r\"[-+]?\\d*\\.?\\d+\", text)\n",
    "    return [float(x) for x in nums]\n",
    "\n",
    "SCRIPT_DIR = Path(__file__).parent if \"__file__\" in globals() else Path.cwd()\n",
    "HEIGHTS_FILE = SCRIPT_DIR / \"heights_1.txt\"\n",
    "WEIGHTS_FILE = SCRIPT_DIR / \"weights_1.txt\"\n",
    "\n",
    "if not HEIGHTS_FILE.exists() or not WEIGHTS_FILE.exists():\n",
    "    print(\"Không tìm thấy tập tin heights_1.txt hoặc weights_1.txt ở thư mục của file này:\")\n",
    "    print(f\"  {SCRIPT_DIR}\")\n",
    "    print(\"Vui lòng đặt hai tập tin vào cùng thư mục với file này hoặc chỉnh lại đường dẫn trong mã.\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# 1-2. \n",
    "height = read_numbers_from_file(HEIGHTS_FILE)   \n",
    "weight = read_numbers_from_file(WEIGHTS_FILE)   \n",
    "\n",
    "arr_height = np.array(height)\n",
    "arr_weight = np.array(weight)\n",
    "\n",
    "# 3-4. \n",
    "INCH_TO_M = 0.0254\n",
    "POUND_TO_KG = 0.453592\n",
    "\n",
    "arr_height_m = arr_height * INCH_TO_M\n",
    "arr_weight_kg = arr_weight * POUND_TO_KG\n",
    "\n",
    "n_height = arr_height.size\n",
    "n_weight = arr_weight.size\n",
    "n_common = min(n_height, n_weight)\n",
    "\n",
    "# 5. \n",
    "if n_common > 0:\n",
    "    arr_bmi = arr_weight_kg[:n_common] / (arr_height_m[:n_common] ** 2)\n",
    "else:\n",
    "    arr_bmi = np.array([])\n",
    "\n",
    "# 6. \n",
    "idx = 50\n",
    "if idx < arr_weight_kg.size:\n",
    "    weight_idx50_kg = arr_weight_kg[idx]\n",
    "else:\n",
    "    weight_idx50_kg = None\n",
    "\n",
    "# 7. \n",
    "start, end = 100, 110\n",
    "if start < arr_height_m.size:\n",
    "    end_index = min(end, arr_height_m.size - 1)\n",
    "    arr_height_m_100 = arr_height_m[start:end_index + 1]\n",
    "else:\n",
    "    arr_height_m_100 = np.array([])\n",
    "\n",
    "# 8. \n",
    "low_bmi_indices = np.where(arr_bmi < 21)[0]\n",
    "low_bmi_values = arr_bmi[low_bmi_indices]\n",
    "\n",
    "# 9. \n",
    "mean_height_m = arr_height_m.mean() if n_height > 0 else None\n",
    "mean_weight_kg = arr_weight_kg.mean() if n_weight > 0 else None\n",
    "\n",
    "# 10. \n",
    "max_height_m = arr_height_m.max() if n_height > 0 else None\n",
    "max_weight_kg = arr_weight_kg.max() if n_weight > 0 else None\n",
    "\n",
    "# 11. \n",
    "min_height_m = arr_height_m.min() if n_height > 0 else None\n",
    "min_weight_kg = arr_weight_kg.min() if n_weight > 0 else None\n",
    "\n",
    "print(f\"Số lượng bản ghi height = {arr_height.size}, weight = {arr_weight.size}\")\n",
    "print()\n",
    "print(\"arr_height (inches) -> arr_height_m (m):\")\n",
    "print(f\"  Ví dụ 10 phần tử đầu: {arr_height_m[:10]}\")\n",
    "print()\n",
    "print(\"arr_weight (pounds) -> arr_weight_kg (kg):\")\n",
    "print(f\"  Ví dụ 10 phần tử đầu: {arr_weight_kg[:10]}\")\n",
    "print()\n",
    "print(f\"arr_bmi (ví dụ 10 đầu): {arr_bmi[:10]}\")\n",
    "print()\n",
    "if weight_idx50_kg is not None:\n",
    "    print(f\"Cân nặng tại index {idx} = {weight_idx50_kg:.3f} kg\")\n",
    "else:\n",
    "    print(f\"Index {idx} vượt quá kích thước mảng (size={arr_weight_kg.size})\")\n",
    "print()\n",
    "print(f\"arr_height_m[{start}:{end}] (bao gồm {end}):\")\n",
    "print(arr_height_m_100)\n",
    "print()\n",
    "print(f\"Số cầu thủ có BMI < 21: {low_bmi_indices.size}\")\n",
    "print(\"Chỉ số (index) và BMI của những người này (tối đa 50 hiển thị):\")\n",
    "for i, b in zip(low_bmi_indices[:50], low_bmi_values[:50]):\n",
    "    print(f\"  index={i}, BMI={b:.3f}\")\n",
    "print()\n",
    "if mean_height_m is not None:\n",
    "    print(f\"Chiều cao trung bình: {mean_height_m:.3f} m\")\n",
    "else:\n",
    "    print(\"Chiều cao trung bình: không có dữ liệu\")\n",
    "if mean_weight_kg is not None:\n",
    "    print(f\"Cân nặng trung bình: {mean_weight_kg:.3f} kg\")\n",
    "else:\n",
    "    print(\"Cân nặng trung bình: không có dữ liệu\")\n",
    "print()\n",
    "if max_height_m is not None:\n",
    "    print(f\"Chiều cao lớn nhất: {max_height_m:.3f} m\")\n",
    "else:\n",
    "    print(\"Chiều cao lớn nhất: không có dữ liệu\")\n",
    "if max_weight_kg is not None:\n",
    "    print(f\"Cân nặng lớn nhất: {max_weight_kg:.3f} kg\")\n",
    "else:\n",
    "    print(\"Cân nặng lớn nhất: không có dữ liệu\")\n",
    "print()\n",
    "if min_height_m is not None:\n",
    "    print(f\"Chiều cao nhỏ nhất: {min_height_m:.3f} m\")\n",
    "else:\n",
    "    print(\"Chiều cao nhỏ nhất: không có dữ liệu\")\n",
    "if min_weight_kg is not None:\n",
    "    print(f\"Cân nặng nhỏ nhất: {min_weight_kg:.3f} kg\")\n",
    "else:\n",
    "    print(\"Cân nặng nhỏ nhất: không có dữ liệu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f44e5f1",
   "metadata": {},
   "source": [
    "BÀI 3.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9deae925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) arr_true:\n",
      " [[ True  True  True]\n",
      " [ True  True  True]\n",
      " [ True  True  True]] \n",
      "\n",
      "2) arr_2D ban đầu:\n",
      " [[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "   sau khi đổi cột 1 <-> 3:\n",
      " [[2 1 0]\n",
      " [5 4 3]\n",
      " [8 7 6]] \n",
      "\n",
      "3) sau khi đổi dòng 1 <-> 2:\n",
      " [[5 4 3]\n",
      " [2 1 0]\n",
      " [8 7 6]] \n",
      "\n",
      "4) sau khi đảo ngược các dòng:\n",
      " [[8 7 6]\n",
      " [2 1 0]\n",
      " [5 4 3]] \n",
      "\n",
      "5) sau khi đảo ngược các cột:\n",
      " [[6 7 8]\n",
      " [0 1 2]\n",
      " [3 4 5]] \n",
      "\n",
      "6) arr_2D_null:\n",
      " [[ 1.  2.  3.]\n",
      " [nan  5.  6.]\n",
      " [ 7. nan  9.]\n",
      " [ 4.  5.  6.]]\n",
      "   Có giá trị rỗng (NaN)? True \n",
      "\n",
      "7) arr_2D_null sau khi thay NaN bằng 0:\n",
      " [[1. 2. 3.]\n",
      " [0. 5. 6.]\n",
      " [7. 0. 9.]\n",
      " [4. 5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def main():\n",
    "    # 1.\n",
    "    arr_true = np.ones((3, 3), dtype=bool)\n",
    "    print(\"1) arr_true:\\n\", arr_true, \"\\n\")\n",
    "\n",
    "    # 2. \n",
    "    arr_1D = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
    "    arr_2D = arr_1D.reshape(3, 3)\n",
    "    arr_swap_cols = arr_2D.copy()\n",
    "    arr_swap_cols[:, [0, 2]] = arr_swap_cols[:, [2, 0]]\n",
    "    print(\"2) arr_2D ban đầu:\\n\", arr_2D)\n",
    "    print(\"   sau khi đổi cột 1 <-> 3:\\n\", arr_swap_cols, \"\\n\")\n",
    "\n",
    "    # 3. \n",
    "    arr_swap_rows = arr_swap_cols.copy()\n",
    "    arr_swap_rows[[0, 1], :] = arr_swap_rows[[1, 0], :]\n",
    "    print(\"3) sau khi đổi dòng 1 <-> 2:\\n\", arr_swap_rows, \"\\n\")\n",
    "\n",
    "    # 4. \n",
    "    arr_flip_rows = arr_swap_rows[::-1, :]\n",
    "    print(\"4) sau khi đảo ngược các dòng:\\n\", arr_flip_rows, \"\\n\")\n",
    "\n",
    "    # 5. \n",
    "    arr_flip_cols = arr_flip_rows[:, ::-1]\n",
    "    print(\"5) sau khi đảo ngược các cột:\\n\", arr_flip_cols, \"\\n\")\n",
    "\n",
    "    # 6. \n",
    "    arr_2D_null = np.array([\n",
    "        [1, 2, 3],\n",
    "        [np.nan, 5, 6],\n",
    "        [7, np.nan, 9],\n",
    "        [4, 5, 6]\n",
    "    ], dtype=float)\n",
    "    has_nan = np.isnan(arr_2D_null).any()\n",
    "    print(\"6) arr_2D_null:\\n\", arr_2D_null)\n",
    "    print(\"   Có giá trị rỗng (NaN)?\", has_nan, \"\\n\")\n",
    "\n",
    "    # 7. \n",
    "    arr_no_nan = np.nan_to_num(arr_2D_null, nan=0.0)\n",
    "    print(\"7) arr_2D_null sau khi thay NaN bằng 0:\\n\", arr_no_nan)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f43a60",
   "metadata": {},
   "source": [
    "BÀI 3.7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "677d1ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kiểu dữ liệu np_baseball: float64\n",
      "Kích thước np_baseball (rows, cols): (5, 2)\n",
      "Không có dòng thứ 50. Số dòng hiện có: 5\n",
      "np_weight (một vài giá trị): [60. 61. 62. 62. 63.]\n",
      "Không có vận động viên thứ 124. Số dòng hiện có: 5\n",
      "Chiều cao trung bình (inch): 172.00\n",
      "Cân nặng trung bình (pounds): 61.60\n",
      "Hệ số tương quan Pearson (height vs weight): 0.9707\n",
      "Nhận xét: Có tương quan thuận: chiều cao tăng kèm theo cân nặng tăng.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "filepath = Path(\"baseball_2D.txt\")\n",
    "\n",
    "# 1\n",
    "baseball = []\n",
    "if not filepath.exists():\n",
    "    raise SystemExit(f\"Không tìm thấy tập tin: {filepath}\")\n",
    "\n",
    "with filepath.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        try:\n",
    "            row = [float(p) for p in parts]\n",
    "        except ValueError:\n",
    "            continue\n",
    "        baseball.append(row)\n",
    "\n",
    "if len(baseball) == 0:\n",
    "    raise SystemExit(\"Danh sách 'baseball' rỗng sau khi đọc file.\")\n",
    "\n",
    "# 2\n",
    "np_baseball = np.array(baseball)\n",
    "\n",
    "print(\"Kiểu dữ liệu np_baseball:\", np_baseball.dtype)\n",
    "print(\"Kích thước np_baseball (rows, cols):\", np_baseball.shape)\n",
    "\n",
    "# 3\n",
    "idx_50 = 49\n",
    "if np_baseball.shape[0] > idx_50:\n",
    "    print(\"Dòng thứ 50 (1-based, index 49):\", np_baseball[idx_50])\n",
    "else:\n",
    "    print(f\"Không có dòng thứ 50. Số dòng hiện có: {np_baseball.shape[0]}\")\n",
    "\n",
    "# 4\n",
    "if np_baseball.shape[1] < 2:\n",
    "    raise SystemExit(\"Dữ liệu không có đủ cột (cần ít nhất 2 cột: chiều cao, cân nặng).\")\n",
    "np_weight = np_baseball[:, 1]\n",
    "print(\"np_weight (một vài giá trị):\", np_weight[:5])\n",
    "\n",
    "# 5\n",
    "idx_124 = 123\n",
    "if np_baseball.shape[0] > idx_124:\n",
    "    height_124 = np_baseball[idx_124, 0]\n",
    "    print(f\"Chiều cao vận động viên thứ 124 (inch): {height_124}\")\n",
    "else:\n",
    "    print(f\"Không có vận động viên thứ 124. Số dòng hiện có: {np_baseball.shape[0]}\")\n",
    "\n",
    "# 6\n",
    "mean_height = np.mean(np_baseball[:, 0])\n",
    "mean_weight = np.mean(np_weight)\n",
    "print(f\"Chiều cao trung bình (inch): {mean_height:.2f}\")\n",
    "print(f\"Cân nặng trung bình (pounds): {mean_weight:.2f}\")\n",
    "\n",
    "# 7\n",
    "if np_baseball.shape[0] >= 2:\n",
    "    corr = np.corrcoef(np_baseball[:, 0], np_weight)[0, 1]\n",
    "    print(f\"Hệ số tương quan Pearson (height vs weight): {corr:.4f}\")\n",
    "\n",
    "    if abs(corr) < 0.1:\n",
    "        conclusion = \"Không có mối tương quan rõ rệt giữa chiều cao và cân nặng.\"\n",
    "    elif corr > 0:\n",
    "        conclusion = \"Có tương quan thuận: chiều cao tăng kèm theo cân nặng tăng.\"\n",
    "    else:\n",
    "        conclusion = \"Có tương quan nghịch: chiều cao tăng kèm theo cân nặng giảm.\"\n",
    "    print(\"Nhận xét:\", conclusion)\n",
    "else:\n",
    "    print(\"Không đủ dữ liệu để tính tương quan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f062c78",
   "metadata": {},
   "source": [
    "BÀI 3.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f56b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np_positions dtype: <U16\n",
      "np_heights dtype: float64\n",
      "Không có GK trong dữ liệu\n",
      "Chiều cao trung bình của các vị trí khác: 2.5\n",
      "players dtype: [('position', '<U3'), ('height', '<f8')]\n",
      "players (chỉ vài phần tử nếu nhiều):\n",
      "[(\"'GK\", 1.) (\"'M'\", 2.) (\"'A'\", 3.) (\"'D'\", 4.)]\n",
      "Chiều cao thấp nhất: 1.0 vị trí: 'GK\n",
      "Chiều cao cao nhất: 4.0 vị trí: 'D'\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "heights_path = Path(\"heights.txt\")\n",
    "positions_path = Path(\"positions.txt\")\n",
    "\n",
    "def read_lines(path):\n",
    "    if not path.exists():\n",
    "        sample_heights = [\"180\", \"175\", \"190\", \"185\"]\n",
    "        sample_positions = [\"GK\", \"M\", \"A\", \"D\"]\n",
    "        if path.name == \"heights.txt\":\n",
    "            path.write_text(\"\\n\".join(sample_heights), encoding=\"utf-8\")\n",
    "            print(f\"{path} không tồn tại: tạo tệp mẫu với {len(sample_heights)} giá trị.\")\n",
    "        elif path.name == \"positions.txt\":\n",
    "            path.write_text(\"\\n\".join(sample_positions), encoding=\"utf-8\")\n",
    "            print(f\"{path} không tồn tại: tạo tệp mẫu với {len(sample_positions)} giá trị.\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Không tìm thấy {path}\")\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "heights = [float(x) for x in read_lines(heights_path)]\n",
    "positions = [x for x in read_lines(positions_path)]\n",
    "\n",
    "if len(heights) != len(positions):\n",
    "    raise ValueError(\"Số lượng heights và positions không bằng nhau\")\n",
    "\n",
    "# 1.a)\n",
    "np_positions = np.array(positions)\n",
    "print(\"np_positions dtype:\", np_positions.dtype)\n",
    "\n",
    "# 1.b)\n",
    "np_heights = np.array(heights)\n",
    "print(\"np_heights dtype:\", np_heights.dtype)\n",
    "\n",
    "# 2) \n",
    "mask_gk = np_positions == \"GK\"\n",
    "if mask_gk.any():\n",
    "    mean_gk = np_heights[mask_gk].mean()\n",
    "    print(\"Chiều cao trung bình của GK:\", mean_gk)\n",
    "else:\n",
    "    print(\"Không có GK trong dữ liệu\")\n",
    "\n",
    "# 3) \n",
    "mask_not_gk = ~mask_gk\n",
    "if mask_not_gk.any():\n",
    "    mean_not_gk = np_heights[mask_not_gk].mean()\n",
    "    print(\"Chiều cao trung bình của các vị trí khác:\", mean_not_gk)\n",
    "else:\n",
    "    print(\"Không có vị trí khác ngoài GK trong dữ liệu\")\n",
    "\n",
    "# 4) \n",
    "dtype_players = np.dtype([(\"position\", \"U3\"), (\"height\", \"f8\")])\n",
    "players = np.zeros(len(heights), dtype=dtype_players)\n",
    "players[\"position\"] = np_positions\n",
    "players[\"height\"] = np_heights\n",
    "\n",
    "print(\"players dtype:\", players.dtype)\n",
    "print(\"players (chỉ vài phần tử nếu nhiều):\")\n",
    "print(players[:10])\n",
    "\n",
    "# 5) \n",
    "players_sorted = np.sort(players, order=\"height\")\n",
    "lowest = players_sorted[0]\n",
    "highest = players_sorted[-1]\n",
    "print(\"Chiều cao thấp nhất:\", lowest[\"height\"], \"vị trí:\", lowest[\"position\"])\n",
    "print(\"Chiều cao cao nhất:\", highest[\"height\"], \"vị trí:\", highest[\"position\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a846ed1",
   "metadata": {},
   "source": [
    "BÀI 3.10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24845b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 2, 'mean': 30.0, 'std': 28.284271247461902, 'min': 10.0, '25%': 20.0, '50%': 30.0, '75%': 40.0, 'max': 50.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_array(vals):\n",
    "    arr = np.array([v if v is not None else np.nan for v in vals], dtype=float)\n",
    "    return arr\n",
    "\n",
    "def describe_with_numpy(vals):\n",
    "    arr = to_array([v for v in vals])  # vals có thể chứa None\n",
    "    if np.isnan(arr).all():\n",
    "        return {\"count\":0,\"mean\":None,\"std\":None,\"min\":None,\"25%\":None,\"50%\":None,\"75%\":None,\"max\":None}\n",
    "    cnt = int(np.count_nonzero(~np.isnan(arr)))\n",
    "    mean = float(np.nanmean(arr))\n",
    "    std = float(np.nanstd(arr, ddof=1)) if cnt > 1 else float(\"nan\")\n",
    "    mn = float(np.nanmin(arr))\n",
    "    p25, p50, p75 = [float(x) for x in np.nanpercentile(arr, [25,50,75])]\n",
    "    mx = float(np.nanmax(arr))\n",
    "    return {\"count\":cnt,\"mean\":mean,\"std\":std,\"min\":mn,\"25%\":p25,\"50%\":p50,\"75%\":p75,\"max\":mx}\n",
    "\n",
    "# Ví dụ dùng cho mỗi continent:\n",
    "# Provide an example `items` list (each element is a tuple like (group_key, record_dict))\n",
    "# Replace this with your actual grouped data when available.\n",
    "items = [\n",
    "    (\"Europe\", {\"wine_servings\": 50}),\n",
    "    (\"Asia\", {\"wine_servings\": None}),\n",
    "    (\"Africa\", {\"wine_servings\": 10})\n",
    "]\n",
    "\n",
    "vals = [it[1].get(\"wine_servings\") for it in items]  # items từ group\n",
    "print(describe_with_numpy(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80c1848",
   "metadata": {},
   "source": [
    "BÀI 3.11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c54f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stocks1 head:\n",
      "(empty)\n",
      "stocks1 tail:\n",
      "(empty)\n",
      "stocks1 dtypes/info:\n",
      "Empty dataframe\n",
      "stocks2 head:\n",
      "(empty)\n",
      "stocks2 tail:\n",
      "(empty)\n",
      "stocks2 dtypes/info:\n",
      "Empty dataframe\n",
      "companies sample:\n",
      "(empty)\n",
      "companies dtypes/info:\n",
      "Empty dataframe\n",
      "stocks combined tail (15):\n",
      "(empty)\n",
      "stocks_companies head (5):\n",
      "(empty)\n",
      "Average open/high/low/close/volume per company (symbol -> dict):\n",
      "Close mean/max/min per company:\n",
      "stocks_companies with result (head 5):\n",
      "(empty)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "\n",
    "# Utility converters\n",
    "def to_float(s):\n",
    "    if s is None or s == '':\n",
    "        return None\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def to_int(s):\n",
    "    if s is None or s == '':\n",
    "        return None\n",
    "    try:\n",
    "        return int(float(s))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def try_parse_date(s):\n",
    "    if s is None or s == '':\n",
    "        return None\n",
    "    fmts = [\n",
    "        \"%Y-%m-%d\",\n",
    "        \"%Y-%m-%d %H:%M:%S\",\n",
    "        \"%d/%m/%Y\",\n",
    "        \"%m/%d/%Y\",\n",
    "        \"%Y/%m/%d\",\n",
    "        \"%Y.%m.%d\",\n",
    "    ]\n",
    "    for f in fmts:\n",
    "        try:\n",
    "            return datetime.strptime(s, f)\n",
    "        except Exception:\n",
    "            continue\n",
    "    try:\n",
    "        return datetime.fromisoformat(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Read CSV with trial delimiters (for companies candidates like .esv)\n",
    "def read_csv_try(path, delimiters=[',', '\\t', ';']):\n",
    "    for d in delimiters:\n",
    "        with open(path, newline='', encoding='utf-8') as f:\n",
    "            f.seek(0)\n",
    "            reader = csv.reader(f, delimiter=d)\n",
    "            rows = list(reader)\n",
    "            if not rows:\n",
    "                continue\n",
    "            if len(rows[0]) > 1:\n",
    "                with open(path, newline='', encoding='utf-8') as f2:\n",
    "                    return list(csv.DictReader(f2, delimiter=d))\n",
    "    with open(path, newline='', encoding='utf-8') as f:\n",
    "        return list(csv.DictReader(f))\n",
    "\n",
    "def read_companies(path_dir='.'):\n",
    "    candidates = ['companies.csv', 'companies.esv', 'companies.tsv']\n",
    "    for fn in candidates:\n",
    "        p = os.path.join(path_dir, fn)\n",
    "        if os.path.exists(p):\n",
    "            return read_csv_try(p)\n",
    "    raise FileNotFoundError(\"companies file not found. Expected companies.csv or companies.esv in current folder.\")\n",
    "\n",
    "# Pretty prints\n",
    "def head(rows, n=5):\n",
    "    return rows[:n]\n",
    "\n",
    "def tail(rows, n=5):\n",
    "    return rows[-n:] if len(rows) >= n else rows\n",
    "\n",
    "def print_rows(rows, n=None):\n",
    "    if not rows:\n",
    "        print(\"(empty)\")\n",
    "        return\n",
    "    cols = list(rows[0].keys())\n",
    "    print(\", \".join(cols))\n",
    "    rows_iter = rows if n is None else rows[:n]\n",
    "    for r in rows_iter:\n",
    "        print(\", \".join((str(r.get(c, \"\")) for c in cols)))\n",
    "\n",
    "def infer_dtypes(rows):\n",
    "    if not rows:\n",
    "        return {}\n",
    "    cols = list(rows[0].keys())\n",
    "    dtypes = {}\n",
    "    for c in cols:\n",
    "        vals = [r.get(c, \"\") for r in rows]\n",
    "        non_null = [v for v in vals if v not in (None, \"\")]\n",
    "        if not non_null:\n",
    "            dtypes[c] = \"object\"\n",
    "            continue\n",
    "        ok_int = True\n",
    "        for v in non_null:\n",
    "            try:\n",
    "                int(float(v))\n",
    "            except Exception:\n",
    "                ok_int = False\n",
    "                break\n",
    "        if ok_int:\n",
    "            dtypes[c] = \"int\"\n",
    "            continue\n",
    "        ok_float = True\n",
    "        for v in non_null:\n",
    "            try:\n",
    "                float(v)\n",
    "            except Exception:\n",
    "                ok_float = False\n",
    "                break\n",
    "        if ok_float:\n",
    "            dtypes[c] = \"float\"\n",
    "            continue\n",
    "        ok_date = True\n",
    "        for v in non_null:\n",
    "            if try_parse_date(v) is None:\n",
    "                ok_date = False\n",
    "                break\n",
    "        if ok_date:\n",
    "            dtypes[c] = \"datetime\"\n",
    "            continue\n",
    "        dtypes[c] = \"object\"\n",
    "    return dtypes\n",
    "\n",
    "def info(rows):\n",
    "    if not rows:\n",
    "        print(\"Empty dataframe\")\n",
    "        return\n",
    "    cols = list(rows[0].keys())\n",
    "    print(f\"Rows: {len(rows)}, Columns: {len(cols)}\")\n",
    "    dtypes = infer_dtypes(rows)\n",
    "    for c in cols:\n",
    "        vals = [r.get(c, \"\") for r in rows]\n",
    "        non_null = sum(1 for v in vals if v not in (None, \"\"))\n",
    "        print(f\"{c}: non-null={non_null}, dtype={dtypes.get(c,'object')}\")\n",
    "\n",
    "# Replace nulls in stocks1 according to rules (high -> max high per symbol, low -> min low per symbol)\n",
    "def fill_high_low_by_symbol(rows):\n",
    "    if not rows:\n",
    "        return rows\n",
    "    # group indices by symbol\n",
    "    groups = defaultdict(list)\n",
    "    for i, r in enumerate(rows):\n",
    "        sym = r.get('symbol', '')\n",
    "        groups[sym].append(i)\n",
    "    for sym, idxs in groups.items():\n",
    "        highs = np.array([np.nan if to_float(rows[i].get('high')) is None else to_float(rows[i].get('high')) for i in idxs], dtype=float)\n",
    "        lows  = np.array([np.nan if to_float(rows[i].get('low')) is None else to_float(rows[i].get('low')) for i in idxs], dtype=float)\n",
    "        # compute replacements if possible\n",
    "        max_high = None\n",
    "        if not np.all(np.isnan(highs)):\n",
    "            max_high = float(np.nanmax(highs))\n",
    "        min_low = None\n",
    "        if not np.all(np.isnan(lows)):\n",
    "            min_low = float(np.nanmin(lows))\n",
    "        # apply\n",
    "        for i in idxs:\n",
    "            if rows[i].get('high') in (None, ''):\n",
    "                rows[i]['high'] = \"\" if max_high is None else str(max_high)\n",
    "            if rows[i].get('low') in (None, ''):\n",
    "                rows[i]['low'] = \"\" if min_low is None else str(min_low)\n",
    "    return rows\n",
    "\n",
    "# Concatenate two lists of dicts (stocks)\n",
    "def concat_rows(a, b):\n",
    "    return list(a) + list(b)\n",
    "\n",
    "# Merge stocks with companies: try match company where company['name'] == stock['symbol'] or company['symbol'] == stock['symbol']\n",
    "def merge_stocks_companies(stocks, companies):\n",
    "    if not stocks:\n",
    "        return []\n",
    "    if not companies:\n",
    "        # just return stocks with no company fields\n",
    "        return [dict(r) for r in stocks]\n",
    "    # build lookup for companies by candidate keys\n",
    "    comp_map = {}\n",
    "    for c in companies:\n",
    "        # prefer explicit keys\n",
    "        for key in ('symbol', 'name'):\n",
    "            if key in c and c.get(key) not in (None, ''):\n",
    "                comp_map.setdefault(str(c.get(key)), []).append(c)\n",
    "    merged = []\n",
    "    for s in stocks:\n",
    "        key = str(s.get('symbol', ''))\n",
    "        matched = comp_map.get(key, [])\n",
    "        if matched:\n",
    "            # if multiple companies match take first\n",
    "            company = matched[0]\n",
    "            # merge without overwriting stock's keys\n",
    "            merged_row = dict(company)  # start with company so we can keep those fields\n",
    "            merged_row.update(s)        # put stock fields (stock fields win)\n",
    "            merged.append(merged_row)\n",
    "        else:\n",
    "            m = dict(s)\n",
    "            # add empty company fields\n",
    "            for col in companies[0].keys():\n",
    "                if col not in m:\n",
    "                    m[col] = \"\"\n",
    "            merged.append(m)\n",
    "    return merged\n",
    "\n",
    "# Aggregations per company using numpy\n",
    "def agg_per_company(stocks, numeric_cols=('open','high','low','close','volume')):\n",
    "    groups = defaultdict(list)\n",
    "    for r in stocks:\n",
    "        groups[r.get('symbol','')].append(r)\n",
    "    results = {}\n",
    "    for sym, rows in groups.items():\n",
    "        arrs = {}\n",
    "        for c in numeric_cols:\n",
    "            vals = np.array([np.nan if to_float(r.get(c)) is None else to_float(r.get(c)) for r in rows], dtype=float)\n",
    "            arrs[c] = vals\n",
    "        res = {}\n",
    "        for c in numeric_cols:\n",
    "            vals = arrs[c]\n",
    "            res[c+'_mean'] = None if np.all(np.isnan(vals)) else float(np.nanmean(vals))\n",
    "        results[sym] = res\n",
    "    return results\n",
    "\n",
    "def close_stats_per_company(stocks):\n",
    "    groups = defaultdict(list)\n",
    "    for r in stocks:\n",
    "        groups[r.get('symbol','')].append(r)\n",
    "    results = {}\n",
    "    for sym, rows in groups.items():\n",
    "        closes = np.array([np.nan if to_float(r.get('close')) is None else to_float(r.get('close')) for r in rows], dtype=float)\n",
    "        if np.all(np.isnan(closes)):\n",
    "            results[sym] = {'close_mean': None, 'close_max': None, 'close_min': None}\n",
    "        else:\n",
    "            results[sym] = {\n",
    "                'close_mean': float(np.nanmean(closes)),\n",
    "                'close_max': float(np.nanmax(closes)),\n",
    "                'close_min': float(np.nanmin(closes)),\n",
    "            }\n",
    "    return results\n",
    "\n",
    "def add_parsed_time(stocks_companies, src_col='date', dest_col='parsed_time'):\n",
    "    for r in stocks_companies:\n",
    "        dt = try_parse_date(r.get(src_col))\n",
    "        r[dest_col] = dt\n",
    "    return stocks_companies\n",
    "\n",
    "def add_result_column(stocks_companies):\n",
    "    for r in stocks_companies:\n",
    "        o = to_float(r.get('open'))\n",
    "        c = to_float(r.get('close'))\n",
    "        if o is None or c is None:\n",
    "            r['result'] = ''\n",
    "        else:\n",
    "            r['result'] = 'up' if c > o else 'down'\n",
    "    return stocks_companies\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cwd = os.getcwd()\n",
    "    # paths\n",
    "    s1_path = os.path.join(cwd, 'stocks1.csv')\n",
    "    s2_path = os.path.join(cwd, 'stocks2.csv')\n",
    "    # read stocks1\n",
    "    if os.path.exists(s1_path):\n",
    "        stocks1 = read_csv_try(s1_path)\n",
    "        print(\"stocks1 head:\")\n",
    "        print_rows(head(stocks1, 5))\n",
    "        print(\"stocks1 tail:\")\n",
    "        print_rows(tail(stocks1, 5))\n",
    "        print(\"stocks1 dtypes/info:\")\n",
    "        info(stocks1)\n",
    "    else:\n",
    "        print(\"stocks1.csv not found in\", cwd)\n",
    "        stocks1 = []\n",
    "    # read stocks2\n",
    "    if os.path.exists(s2_path):\n",
    "        stocks2 = read_csv_try(s2_path)\n",
    "        print(\"stocks2 head:\")\n",
    "        print_rows(head(stocks2, 5))\n",
    "        print(\"stocks2 tail:\")\n",
    "        print_rows(tail(stocks2, 5))\n",
    "        print(\"stocks2 dtypes/info:\")\n",
    "        info(stocks2)\n",
    "    else:\n",
    "        print(\"stocks2.csv not found in\", cwd)\n",
    "        stocks2 = []\n",
    "    # read companies\n",
    "    try:\n",
    "        companies = read_companies(cwd)\n",
    "        print(\"companies sample:\")\n",
    "        print_rows(head(companies, 5))\n",
    "        print(\"companies dtypes/info:\")\n",
    "        info(companies)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        companies = []\n",
    "\n",
    "    # 2. check nulls in stocks1 and fill\n",
    "    if stocks1:\n",
    "        # check nulls\n",
    "        any_null = any(any(v in (None, '') for v in r.values()) for r in stocks1)\n",
    "        print(\"stocks1 has nulls:\", any_null)\n",
    "        stocks1 = fill_high_low_by_symbol(stocks1)\n",
    "        print(\"After filling high/low in stocks1 (head):\")\n",
    "        print_rows(head(stocks1, 5))\n",
    "    # 3. concat stocks\n",
    "    stocks = concat_rows(stocks1, stocks2)\n",
    "    print(\"stocks combined tail (15):\")\n",
    "    print_rows(tail(stocks, 15))\n",
    "    # 4. merge stocks and companies\n",
    "    stocks_companies = merge_stocks_companies(stocks, companies) if stocks else []\n",
    "    print(\"stocks_companies head (5):\")\n",
    "    print_rows(head(stocks_companies, 5))\n",
    "    # 5. average prices and volume per company\n",
    "    aggs = agg_per_company(stocks)\n",
    "    print(\"Average open/high/low/close/volume per company (symbol -> dict):\")\n",
    "    for k, v in aggs.items():\n",
    "        print(k, v)\n",
    "    # 6. close stats per company\n",
    "    closes = close_stats_per_company(stocks)\n",
    "    print(\"Close mean/max/min per company:\")\n",
    "    for k, v in closes.items():\n",
    "        print(k, v)\n",
    "    # 7. add parsed_time\n",
    "    stocks_companies = add_parsed_time(stocks_companies, src_col='date', dest_col='parsed_time')\n",
    "    if stocks_companies:\n",
    "        print(\"Type of parsed_time column:\", type(stocks_companies[0].get('parsed_time')))\n",
    "        print_rows(head(stocks_companies, 5))\n",
    "    # 8. add result column\n",
    "    stocks_companies = add_result_column(stocks_companies)\n",
    "    print(\"stocks_companies with result (head 5):\")\n",
    "    print_rows(head(stocks_companies, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
